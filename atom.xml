<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Rottens&#39;s blog</title>
  <subtitle>努力什么时候都不会晚，加油！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://github.com/chengu/chengu.github.io/"/>
  <updated>2017-08-30T15:23:10.000Z</updated>
  <id>https://github.com/chengu/chengu.github.io/</id>
  
  <author>
    <name>Rottens</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Oracle linux下部署分布式redis、分布式mongo</title>
    <link href="https://github.com/chengu/chengu.github.io/2017/08/30/Oracle-linux%E4%B8%8B%E9%83%A8%E7%BD%B2%E5%88%86%E5%B8%83%E5%BC%8Fredis%E3%80%81%E5%88%86%E5%B8%83%E5%BC%8Fmongo/"/>
    <id>https://github.com/chengu/chengu.github.io/2017/08/30/Oracle-linux下部署分布式redis、分布式mongo/</id>
    <published>2017-08-30T15:22:01.000Z</published>
    <updated>2017-08-30T15:23:10.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>将Centos的yum源更换为国内的阿里云源</title>
    <link href="https://github.com/chengu/chengu.github.io/2017/07/31/%E5%B0%86Centos%E7%9A%84yum%E6%BA%90%E6%9B%B4%E6%8D%A2%E4%B8%BA%E5%9B%BD%E5%86%85%E7%9A%84%E9%98%BF%E9%87%8C%E4%BA%91%E6%BA%90/"/>
    <id>https://github.com/chengu/chengu.github.io/2017/07/31/将Centos的yum源更换为国内的阿里云源/</id>
    <published>2017-07-31T07:14:03.000Z</published>
    <updated>2017-07-31T07:21:33.000Z</updated>
    
    <content type="html"><![CDATA[<p>有的时候yum安装一些软件，直接404或者timeout，此时可以更改为国内的源。<br>阿里云Linux安装软件镜像源<br>阿里云是最近新出的一个镜像源。得益与阿里云的高速发展，这么大的需求，肯定会推出自己的镜像源。<br>阿里云Linux安装镜像源地址：<a href="http://mirrors.aliyun.com/" target="_blank" rel="external">http://mirrors.aliyun.com/</a><br>CentOS系统更换软件安装源<br>第一步：备份你的原镜像文件，以免出错后可以恢复。<br><code>mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup</code></p>
<p>第二步：下载新的CentOS-Base.repo 到/etc/yum.repos.d/<br>CentOS 6<br><code>wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo</code><br>CentOS 7<br><code>wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</code><br>第三步：运行yum makecache生成缓存<br>yum clean all<br>yum makecache</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;有的时候yum安装一些软件，直接404或者timeout，此时可以更改为国内的源。&lt;br&gt;阿里云Linux安装软件镜像源&lt;br&gt;阿里云是最近新出的一个镜像源。得益与阿里云的高速发展，这么大的需求，肯定会推出自己的镜像源。&lt;br&gt;阿里云Linux安装镜像源地址：&lt;a href
    
    </summary>
    
      <category term="Question" scheme="https://github.com/chengu/chengu.github.io/categories/Question/"/>
    
    
      <category term="问题汇总" scheme="https://github.com/chengu/chengu.github.io/tags/%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch学习(一)</title>
    <link href="https://github.com/chengu/chengu.github.io/2017/07/27/Elasticsearch%E5%AD%A6%E4%B9%A0-%E4%B8%80/"/>
    <id>https://github.com/chengu/chengu.github.io/2017/07/27/Elasticsearch学习-一/</id>
    <published>2017-07-27T12:31:11.000Z</published>
    <updated>2017-07-27T15:24:05.000Z</updated>
    
    <content type="html"><![CDATA[<p>对于全文检索，只是在刚毕业时研究过sphinx的皮毛，当时项目中选用了sphinx的中文版coreseek，感觉真心强大。而在后来的工作中，也没有再去深入的研究过，而之后看到的文章中，提到最多的只有Solr、Lucene、Elasticsearch这三个基于java的全文检索库，今天工作之余，好好研究一番。</p>
<p>先做了下术语调查，发现Solr与Lucene现在都是Apache基金在维护，Lucene只是一个java框架，如果想使用的话必须要使用java，在程序中集成，了解其原理，所以要求相对较高了。而Solr是最流行的企业级搜索引擎，Solr4 还增加了NoSQL支持，它成熟稳定，还支持html、pdf、doc、xls、json、xml、csv等多种格式的索引。但其缺点也相对明显，数据量增大、搜索效率会降低，实时搜索会阻塞io，效率不高。<br>Elasticsearch是一个建立在全文搜索引擎 Apache Lucene™ 基础上的搜索引擎，可以说Lucene是当今最先进，最高效的全功能开源搜索引擎框架，使用它做全文搜索时，只需要使用统一开发好的API即可，而不需要了解其背后复杂的Lucene的运行原理。它在全文搜索、实时搜索、分布式搜索、无缝扩展机器处理pb级别数据等方面都非常出色。因此，这里我选择研究Elasticsearch，并记录下自己的所有理解。</p>
<ol>
<li><p>安装<br>首先从官网下载安装包：<a href="https://www.elastic.co/downloads/elasticsearch，这里我下载的是zip包，版本5.5.1。" target="_blank" rel="external">https://www.elastic.co/downloads/elasticsearch，这里我下载的是zip包，版本5.5.1。</a><br>接下来解压文件<br><code>unzip elasticsearch-5.5.1.zip</code>  </p>
<p>接下来安装marvel插件，marvel一个管理和监控的工具，是个插件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd elasticsearch-5.5.1</div><div class="line">./bin/plugin -i elasticsearch/marvel/latest</div></pre></td></tr></table></figure>
<p>此时，如果想关闭监控，则可以使用以下命令：<br><code>echo &#39;marvel.agent.enabled: false&#39; &gt;&gt; ./config/elasticsearch.yml</code></p>
</li>
<li><p>运行<br>./bin/elasticsearch<br>此时如果只有本地访问，则可以修改配置文件 elasticsearch.yml中network.host(注意配置文件格式不是以#开头的要空一格，：后要空一格) 为network.host: 0.0.0.0<br>如果想在后台以守护进程模式运行，添加-d参数。</p>
</li>
<li><p>测试<br>执行下面的测试命令即可以看到结果<br><code>curl &#39;http://localhost:9200/?pretty&#39;</code><br>也可以使用下面命令来关闭它：<br><code>curl -XPOST &#39;http://localhost:9200/_shutdown&#39;</code></p>
</li>
<li>查看marvel和sense<br>如果你安装了Marvel（作为管理和监控的工具），就可以在浏览器里通过以下地址访问它：<br><a href="http://localhost:9200/_plugin/marvel/" target="_blank" rel="external">http://localhost:9200/_plugin/marvel/</a><br>你可以在Marvel中通过点击dashboards，在下拉菜单中访问Sense开发者控制台，或者直接访问以下地址：<br><a href="http://localhost:9200/_plugin/marvel/sense/" target="_blank" rel="external">http://localhost:9200/_plugin/marvel/sense/</a></li>
<li>端口及通信<br>java客户端分为节点客户端(只加入集群、无数据存储)、传输客户端(不加入集群，只请求至节点客户端)，两种客户端与集群的交互端口均为9300，假设不开此端口，则不会组 成集群，9200端口则是其他语言通过restful api的形式与Elasticsearch进行通信。</li>
</ol>
<h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><p>Elasticsearch以json结构的文档存储。Elasticsearch集群可以包含多个索引(indices)（数据库），每一个索引可以包含多个类型(types)（表），每一个类型包含多个文档(documents)（行），然后每个文档包含多个字段(Fields)（列）。倒排索引 传统数据库为特定列增加一个索引，例如B-Tree索引来加速检索。Elasticsearch和Lucene使用一种叫做倒排索引(inverted index)的数据结构来达到相同目的。<br>与传统关系型数据库的类比图<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Relational DB -&gt; Databases -&gt; Tables -&gt; Rows -&gt; Columns</div><div class="line">Elasticsearch -&gt; Indices   -&gt; Types  -&gt; Documents -&gt; Fields</div></pre></td></tr></table></figure></p>
<p>简单例子如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">PUT /megacorp/employee/1</div><div class="line">&#123;</div><div class="line">	&quot;first_name&quot; : &quot;John&quot;,</div><div class="line">	&quot;last_name&quot; :  &quot;Smith&quot;,</div><div class="line">	&quot;age&quot; :        25,</div><div class="line">	&quot;about&quot; :      &quot;I love to go rock climbing&quot;,</div><div class="line">	&quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>其中megacorp：索引名，employee：类型名；1：这个员工的ID。(另外，再put一次，则更新此文档)</p>
<h6 id="检索"><a href="#检索" class="headerlink" title="检索"></a>检索</h6><p>获取的一条数据，保存在_source节点里<br><code>GET /megacorp/employee/1</code></p>
<p>简单搜索，默认搜索结果10条，结果保存在hits数组节点里。<br><code>GET /megacorp/employee/_search</code></p>
<p>查询搜索，结果也在hits数组节点里<br><code>GET /megacorp/employee/_search?q=last_name:Smith</code></p>
<p>使用DSL(Domain Specific Language特定领域语言)语句查询<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">GET /megacorp/employee/_search</div><div class="line">&#123;</div><div class="line">	&quot;query&quot; : &#123;</div><div class="line">		&quot;match&quot; : &#123;</div><div class="line">			&quot;last_name&quot; : &quot;Smith&quot;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>带过滤器的搜索<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">GET /megacorp/employee/_search</div><div class="line">&#123;</div><div class="line">	&quot;query&quot; : &#123;</div><div class="line">		&quot;filtered&quot; : &#123;</div><div class="line">			&quot;filter&quot; : &#123;</div><div class="line">				&quot;range&quot; : &#123;</div><div class="line">					&quot;age&quot; : &#123; &quot;gt&quot; : 30 &#125; &lt;1&gt;</div><div class="line">				&#125;</div><div class="line">	        &#125;,</div><div class="line">			&quot;query&quot; : &#123;</div><div class="line">				&quot;match&quot; : &#123;</div><div class="line">					&quot;last_name&quot; : &quot;smith&quot; &lt;2&gt;</div><div class="line">				&#125;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>搜索短语：如果match_phrase改为match，则会搜索出包含rock或者climbing的结果<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">GET /megacorp/employee/_search</div><div class="line">&#123;</div><div class="line">	&quot;query&quot; : &#123;</div><div class="line">		&quot;match_phrase&quot; : &#123;</div><div class="line">			&quot;about&quot; : &quot;rock climbing&quot;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>搜索结果高亮：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">GET /megacorp/employee/_search</div><div class="line">&#123;</div><div class="line">	&quot;query&quot; : &#123;</div><div class="line">		&quot;match_phrase&quot; : &#123;</div><div class="line">			&quot;about&quot; : &quot;rock climbing&quot;</div><div class="line">        &#125;</div><div class="line">    &#125;,</div><div class="line">	&quot;highlight&quot;: &#123;</div><div class="line">		&quot;fields&quot; : &#123;</div><div class="line">	        &quot;about&quot; : &#123;&#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h6 id="聚合，就是完成数据的统计分析，类似于sql的group-by"><a href="#聚合，就是完成数据的统计分析，类似于sql的group-by" class="headerlink" title="聚合，就是完成数据的统计分析，类似于sql的group by"></a>聚合，就是完成数据的统计分析，类似于sql的group by</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">GET /megacorp/employee/_search</div><div class="line">&#123;</div><div class="line">	&quot;aggs&quot;: &#123;</div><div class="line">		&quot;all_interests&quot;: &#123;</div><div class="line">			&quot;terms&quot;: &#123; &quot;field&quot;: &quot;interests&quot; &#125;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>返回结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">	...</div><div class="line">	&quot;hits&quot;: &#123; ... &#125;,</div><div class="line">	&quot;aggregations&quot;: &#123;</div><div class="line">		&quot;all_interests&quot;: &#123;</div><div class="line">			&quot;buckets&quot;: [</div><div class="line">			&#123;</div><div class="line">				&quot;key&quot;:       &quot;music&quot;,</div><div class="line">		       &quot;doc_count&quot;: </div><div class="line">			&#125;,</div><div class="line">			&#123;</div><div class="line">				&quot;key&quot;:       &quot;forestry&quot;,</div><div class="line">				&quot;doc_count&quot;: 1</div><div class="line">			&#125;,</div><div class="line">			&#123;</div><div class="line">				&quot;key&quot;:       &quot;sports&quot;,</div><div class="line">				&quot;doc_count&quot;: 1</div><div class="line">			&#125;</div><div class="line">			]</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>加上搜索语句的聚合<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">GET /megacorp/employee/_search</div><div class="line">&#123;</div><div class="line">	&quot;query&quot;: &#123;</div><div class="line">		&quot;match&quot;: &#123;</div><div class="line">			&quot;last_name&quot;: &quot;smith&quot;</div><div class="line">		&#125;</div><div class="line">	&#125;,</div><div class="line">	&quot;aggs&quot;: &#123;</div><div class="line">		&quot;all_interests&quot;: &#123;</div><div class="line">			&quot;terms&quot;: &#123;</div><div class="line">				&quot;field&quot;: &quot;interests&quot;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>返回结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">...</div><div class="line">&quot;all_interests&quot;: &#123;</div><div class="line">	&quot;buckets&quot;: [</div><div class="line">	&#123;</div><div class="line">		&quot;key&quot;: &quot;music&quot;,</div><div class="line">			&quot;doc_count&quot;: 2</div><div class="line">	&#125;,</div><div class="line">	&#123;</div><div class="line">		&quot;key&quot;: &quot;sports&quot;,</div><div class="line">		&quot;doc_count&quot;: 1</div><div class="line">	&#125;</div><div class="line">	]</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>聚合也允许分级汇总。例如，让我们统计每种兴趣下职员的平均年龄：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">GET /megacorp/employee/_search</div><div class="line">&#123;</div><div class="line">	&quot;aggs&quot; : &#123;</div><div class="line">		&quot;all_interests&quot; : &#123;</div><div class="line">			&quot;terms&quot; : &#123; &quot;field&quot; : &quot;interests&quot; &#125;,</div><div class="line">				&quot;aggs&quot; : &#123;</div><div class="line">					&quot;avg_age&quot; : &#123;</div><div class="line">						&quot;avg&quot; : &#123; &quot;field&quot; : &quot;age&quot; &#125;</div><div class="line">					&#125;</div><div class="line">				&#125;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>返回结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">...</div><div class="line">&quot;all_interests&quot;: &#123;</div><div class="line">	&quot;buckets&quot;: [</div><div class="line">	&#123;</div><div class="line">		&quot;key&quot;: &quot;music&quot;,</div><div class="line">			&quot;doc_count&quot;: 2,</div><div class="line">			&quot;avg_age&quot;: &#123;</div><div class="line">				&quot;value&quot;: 28.5</div><div class="line">			&#125;</div><div class="line">	&#125;,</div><div class="line">	&#123;</div><div class="line">		&quot;key&quot;: &quot;forestry&quot;,</div><div class="line">		&quot;doc_count&quot;: 1,</div><div class="line">		&quot;avg_age&quot;: &#123;</div><div class="line">			&quot;value&quot;: 35</div><div class="line">		&#125;</div><div class="line">	&#125;,</div><div class="line">	&#123;</div><div class="line">		&quot;key&quot;: &quot;sports&quot;,</div><div class="line">		&quot;doc_count&quot;: 1,</div><div class="line">		&quot;avg_age&quot;: &#123;</div><div class="line">			&quot;value&quot;: 25</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">	]</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对于全文检索，只是在刚毕业时研究过sphinx的皮毛，当时项目中选用了sphinx的中文版coreseek，感觉真心强大。而在后来的工作中，也没有再去深入的研究过，而之后看到的文章中，提到最多的只有Solr、Lucene、Elasticsearch这三个基于java的全文检
    
    </summary>
    
      <category term="全文检索" scheme="https://github.com/chengu/chengu.github.io/categories/%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2/"/>
    
    
      <category term="Elasticsearch" scheme="https://github.com/chengu/chengu.github.io/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>selenium+phantomjs抓取动态网页数据</title>
    <link href="https://github.com/chengu/chengu.github.io/2016/07/18/selenium-phantomjs%E6%8A%93%E5%8F%96%E5%8A%A8%E6%80%81%E7%BD%91%E9%A1%B5%E6%95%B0%E6%8D%AE/"/>
    <id>https://github.com/chengu/chengu.github.io/2016/07/18/selenium-phantomjs抓取动态网页数据/</id>
    <published>2016-07-18T08:01:01.000Z</published>
    <updated>2017-07-18T14:20:15.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>接到fang88的技术考核题，要求如下</strong>:</p>
<ol>
<li>使用python3</li>
<li>只写一个crawl.py文件，传递url参数<blockquote>
<p><strong>url示例</strong>：<br><a href="https://www.lennar.com/new-homes/washington/seattle" target="_blank" rel="external">https://www.lennar.com/new-homes/washington/seattle</a><br><a href="https://www.lennar.com/new-homes/texas/houston" target="_blank" rel="external">https://www.lennar.com/new-homes/texas/houston</a></p>
</blockquote>
</li>
<li>爬取后的数据ajax抛给指定的接口。</li>
</ol>
<hr>
<p>因为经常会爬一些数据，所以大体看了一下，就一个网址，感觉应该挺简单的。<br>考虑到平时都用py2的scrapy来做爬虫，今天正好再熟悉下py3，也没有用bs4，因为最近发现lxml的xpath解析挺爽的<br>直接代码开撸，嘿嘿！</p>
<p>首先，根据要求，需要拿到参数，命令行如下:<br><code>python3 crawl.py https://www.lennar.com/new-homes/washington/seattle</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">if len(argv) != 2:</div><div class="line">	print(&apos;参数格式错误&apos;)</div><div class="line">else:</div><div class="line">	print(argv[1])</div></pre></td></tr></table></figure></p>
<p>开始分析网址、抓取数据，分析网页内容，发现都是动态数据，因此选择用selenium和phantomjs来抓取<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">driver = webdriver.PhantomJS(executable_path=&apos;/Users/apple/Downloads/phantomjs-2.1.1-macosx/bin/phantomjs&apos;)</div><div class="line">driver.get(url)</div><div class="line">selector = etree.HTML(driver.page_source.encode(&apos;utf-8&apos;))</div><div class="line">items = selector.xpath(&apos;//div[@class=&quot;comm-item clearfix&quot;]&apos;)</div><div class="line">	for item in items:</div><div class="line">		temp = item.xpath(&apos;./h1/a/text()&apos;)</div><div class="line">		name = temp[0] if len(temp) &gt; 0 else &apos;&apos;</div><div class="line">		temp = item.xpath(&apos;./h2/a/text()&apos;)</div><div class="line">		name = name + &apos; &apos; + (temp[0] if len(temp) &gt; 0 else &apos;&apos;)</div><div class="line">		print(name)</div></pre></td></tr></table></figure></p>
<p>通过上述代码，很快就抓到首页要的内容，接下来准备抓分页，发现是#标签，然后用chrome来network检查元素，查看post的接口，找到相关的，但post的参数太多，所以想用之前做模拟登陆时的模拟点击来实现，代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">driver.find_element_by_xpath(&apos;//div[@class=&quot;sptop&quot;]//a[@class=&quot;ir next&quot;]&apos;).click()</div></pre></td></tr></table></figure></p>
<p>运行调试，报错了：<br><code>ElementNotVisibleException</code><br>通过报错，然后按以往的经验，加上延时，发现仍然无效，不明所以之后，尝试其他链接的模拟点击，发现可以。最后选择最原始也是最有效的调用js方法来解决。(如果有哪位高人知道原因，可以告诉我，非常感谢)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">with open(&apos;test.html&apos;, &apos;w+&apos;) as f:</div><div class="line">	f.write(driver.page_source)</div></pre></td></tr></table></figure></p>
<p>保存下网页，去查看相关的js及变量的内容。通过检查发现调用了两个接口，先做第一个接口，分析参数为页面里js的变量，于是通过js来得到:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">acetParams = driver.execute_script(&quot;return facetContextJSON.params&quot;)</div><div class="line">pageState = driver.execute_script(&quot;return pageState&quot;)</div></pre></td></tr></table></figure></p>
<p>接着通过postman来抓取的header，复制进去，并通过xpath抓取到总页数，通过requests来获取json数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">def get_otherpage(page, facetParams, pageState, headers):</div><div class="line">	pageState[&apos;pn&apos;] = page</div><div class="line">	payload = json.dumps(&#123;&apos;searchState&apos;:facetParams, &apos;pageState&apos;: pageState&#125;)</div><div class="line">	url = &apos;https://cn.lennar.com/Services/REST/Facets.svc/GetFacetResults&apos;</div><div class="line">	response = requests.request(&quot;POST&quot;, url, data=payload, headers=headers)</div></pre></td></tr></table></figure></p>
<p>发现成功获取json结果，接着分析第二个接口，参数是第一个接口的返回部分数据，执行代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">url = &quot;https://cn.lennar.com/Services/Rest/SearchMethods.svc/GetCommunityDetails&quot;</div><div class="line">pageState.update(&#123;&quot;pt&quot;:&quot;C&quot;,&quot;ic&quot;:19,&quot;ss&quot;:0,&quot;attr&quot;:&quot;No    ne&quot;,&quot;ius&quot;:False&#125;)</div><div class="line">payload = json.dumps(&#123;&apos;facetResults&apos;: response.json()[&apos;fr&apos;], &apos;pageState&apos;:pageState&#125;)</div><div class="line">response = requests.request(&quot;POST&quot;, url, data=payload, headers=headers)</div><div class="line">for item in response.json():</div><div class="line">	name = item[&apos;cnm&apos;]</div><div class="line">	if item[&apos;mcm&apos;]:</div><div class="line">		name += item[&apos;mcm&apos;]</div><div class="line">	print(name)</div></pre></td></tr></table></figure></p>
<p>到此，所有需求的数据都可以得到了。因为只是测试，所以没有封装成类，也直接使用了postman抓到的cookie.<br>测试代码在<a href="https://github.com/chengu/simple_crawls/blob/master/fang88.py">github</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;接到fang88的技术考核题，要求如下&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用python3&lt;/li&gt;
&lt;li&gt;只写一个crawl.py文件，传递url参数&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;url示例&lt;/strong&gt;：&lt;br&gt;&lt;a
    
    </summary>
    
      <category term="Python" scheme="https://github.com/chengu/chengu.github.io/categories/Python/"/>
    
    
      <category term="爬虫" scheme="https://github.com/chengu/chengu.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>mac系统下，用excel打开csv文件，中文乱码问题</title>
    <link href="https://github.com/chengu/chengu.github.io/2014/03/25/mac%E7%B3%BB%E7%BB%9F%E4%B8%8B%EF%BC%8C%E7%94%A8excel%E6%89%93%E5%BC%80csv%E6%96%87%E4%BB%B6%EF%BC%8C%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98/"/>
    <id>https://github.com/chengu/chengu.github.io/2014/03/25/mac系统下，用excel打开csv文件，中文乱码问题/</id>
    <published>2014-03-25T05:21:26.000Z</published>
    <updated>2017-07-31T07:18:57.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>csv中文乱码问题</strong></p>
<p>今天要导出在mongo的数据，直接输入命令<br><code>mongoexport -d test -c testitem --type=csv -f name,phone,tel,address -o ./test.csv</code></p>
<p>导出后直接用excel打开，发现中文全是乱码。于是google，发现用excel导入文本的方式也出错(可能是我的文件里本身数据有一些格式问题)、使用sublime另存utf-8格式也是不行。很是纠结，正准备自己写个脚本来完成的时候，找到了问题的解决方法：<br>命令行输入：<br><code>iconv -f UTF8 -t GB18030 test.csv &gt;test_new.csv</code><br>发现好使。</p>
<p>另外一种方式：直接将mac电脑上导出的test.csv发到windows上，用wps打开也是正常的，另存为xls格式，再发回mac上，用excel打开也是正常的了。</p>
<p>特做此备忘遇坑问题记录！！！</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;csv中文乱码问题&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;今天要导出在mongo的数据，直接输入命令&lt;br&gt;&lt;code&gt;mongoexport -d test -c testitem --type=csv -f name,phone,tel,address -o 
    
    </summary>
    
      <category term="Question" scheme="https://github.com/chengu/chengu.github.io/categories/Question/"/>
    
    
      <category term="遇坑记录" scheme="https://github.com/chengu/chengu.github.io/tags/%E9%81%87%E5%9D%91%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
</feed>
